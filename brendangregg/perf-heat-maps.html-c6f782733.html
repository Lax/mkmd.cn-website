<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>perf Heat Maps</title>
        <meta name="viewport" content="width=device-width">

        <!-- syntax highlighting CSS -->
        <link rel="stylesheet" href="/blog/css/syntax.css">

        <!-- Custom CSS -->
        <link rel="stylesheet" href="/blog/css/main.css">

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7747513-3']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

    </head>
    <body>

	<div class="nav">
	<p class="navhdr">This Site:</p>
<a href="/index.html">Homepage</a><br>
<a href="/blog/index.html">Blog</a><br>
<a href="/sitemap.html">Full Site Map</a><br>
<a href="/sysperfbook.html">Sys Perf book</a><br>
<a href="/linuxperf.html">Linux Perf</a><br>
<a href="/methodology.html">Perf Methods</a><br>
<a href="/usemethod.html">USE Method</a><br>
<a href="/tsamethod.html">TSA Method</a><br>
<a href="/offcpuanalysis.html">Off-CPU Analysis</a><br>
<a href="/activebenchmarking.html">Active Bench.</a><br>
<a href="/flamegraphs.html">Flame Graphs</a><br>
<a href="/heatmaps.html">Heat Maps</a><br>
<a href="/frequencytrails.html">Frequency Trails</a><br>
<a href="/colonygraphs.html">Colony Graphs</a><br>
<a href="/perf.html">perf Examples</a><br>
<a href="/ktap.html">ktap Examples</a><br>
<a href="/dtrace.html">DTrace Tools</a><br>
<a href="/dtracetoolkit.html">DTraceToolkit</a><br>
<a href="/dtkshdemos.html">DtkshDemos</a><br>
<a href="/guessinggame.html">Guessing Game</a><br>
<a href="/specials.html">Specials</a><br>
<a href="/books.html">Books</a><br>
<a href="/sites.html">Other Sites</a><br>

	</div>

	<div class="recent">
	Recent posts:<br>
	<ul style="padding-left:18px">
	  
		   <li>30 Aug 2014 &raquo;<br>
		   <a href="/blog/2014-08-30/ftrace-the-hidden-light-switch.html">  
		   ftrace: The Hidden Light Switch</a></li>
	  
		   <li>23 Aug 2014 &raquo;<br>
		   <a href="/blog/2014-08-23/linux-perf-tools-linuxcon-na-2014.html">  
		   Linux Performance Tools at LinuxCon North America 2014</a></li>
	  
		   <li>28 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-28/execsnoop-for-linux.html">  
		   execsnoop For Linux: See Short-Lived Processes</a></li>
	  
		   <li>25 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-25/opensnoop-for-linux.html">  
		   opensnoop For Linux</a></li>
	  
		   <li>23 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-23/linux-iosnoop-latency-heat-maps.html">  
		   Linux iosnoop Latency Heat Maps</a></li>
	  
		   <li>16 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-16/iosnoop-for-linux.html">  
		   iosnoop For Linux</a></li>
	  
		   <li>13 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-13/linux-ftrace-function-counting.html">  
		   Linux ftrace Function Counting</a></li>
	  
		   <li>10 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-10/perf-hacktogram.html">  
		   perf Hacktogram</a></li>
	  
		   <li>03 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-03/perf-counting.html">  
		   perf Counting</a></li>
	  
		   <li>01 Jul 2014 &raquo;<br>
		   <a href="/blog/2014-07-01/perf-heat-maps.html">  
		   perf Heat Maps</a></li>
	  
		   <li>29 Jun 2014 &raquo;<br>
		   <a href="/blog/2014-06-29/perf-static-tracepoints.html">  
		   perf Static Tracepoints</a></li>
	  
		   <li>22 Jun 2014 &raquo;<br>
		   <a href="/blog/2014-06-22/perf-cpu-sample.html">  
		   perf CPU Sampling</a></li>
	  
		   <li>12 Jun 2014 &raquo;<br>
		   <a href="/blog/2014-06-12/java-flame-graphs.html">  
		   Java Flame Graphs</a></li>
	  
		   <li>09 Jun 2014 &raquo;<br>
		   <a href="/blog/2014-06-09/java-cpu-sampling-using-hprof.html">  
		   Java CPU Sampling Using hprof</a></li>
	  
		   <li>23 May 2014 &raquo;<br>
		   <a href="/blog/2014-05-23/osx-10.9.3-is-toxic.html">  
		   OS X 10.9.3 Recurring Panics</a></li>
	  
		   <li>17 May 2014 &raquo;<br>
		   <a href="/blog/2014-05-17/free-as-in-we-own-your-ip.html">  
		   Free, as in, We Own Your IP</a></li>
	  
		   <li>16 May 2014 &raquo;<br>
		   <a href="/blog/2014-05-16/LISA13-metrics-workshop.html">  
		   LISA13 Metrics Workshop</a></li>
	  
		   <li>11 May 2014 &raquo;<br>
		   <a href="/blog/2014-05-11/strace-wow-much-syscall.html">  
		   strace Wow Much Syscall</a></li>
	  
		   <li>09 May 2014 &raquo;<br>
		   <a href="/blog/2014-05-09/xen-feature-detection.html">  
		   Xen Feature Detection</a></li>
	  
		   <li>07 May 2014 &raquo;<br>
		   <a href="/blog/2014-05-07/what-color-is-your-xen.html">  
		   What Color Is Your Xen?</a></li>
	  
	</ul>
	<a href="/blog/index.html">Blog index</a><br>
	<a href="/blog/about.html">About</a><br>
	<a href="/blog/rss.xml">RSS</a><br>
	</div>

        <div class="site">
          <div class="header">
            <h1 class="title"><a href="/blog/index.html">Brendan Gregg's Blog</a></h1>
            <a class="extra" href="/blog/index.html">home</a>
          </div>

          <h2 class="big">perf Heat Maps</h2>
<p class="meta">01 Jul 2014</p>

<div class="post">
<p>This is disk latency of an AWS EC2 c3.large instance (ubuntu), shown as a <a href="/HeatMaps/latency.html">latency heat map</a>:</p>

<p><object data="/blog/images/2014/out.lat.svg" type="image/svg+xml" width=720 height=363>
<img src="/blog/images/2014/out.lat.png" width=720 height=363 />
</object></p>

<p>Woah, aren&#39;t these disks supposed to be SSDs?</p>

<p>Mouse over pixels for details. Here is the <a href="/blog/images/2014/out.lat.svg">SVG</a>, and a zoomed <a href="/blog/images/2014/out.latzoom.svg">SVG to 15ms</a>. Time is on the x-axis, and latency on the y-axis. The color shows how many I/O fell into that time and latency range: darker for more.</p>

<p>There is a latency spike at the 63 second mark, which exceeds 237 ms. Yikes. Around the 43 second mark a cloud of latency begins, reaching around 30 ms, which is also worrying for SSDs.</p>

<p>Perhaps there is a simple explanation: load. Bursts of I/O could cause the spikes, thanks to queueing on the device. And the latency cloud could be explained by an increase in the rate of requested I/O at the 43 second mark. I generated line graphs to check these theories:</p>

<p><a href="/blog/images/2014/storageio.png"><img border=0 src="/blog/images/2014/storageio.png" width=700 height=163 /></a></p>

<p>This shows no workload bursts or increases that would explain the changes in latency.</p>

<p>I was creating an example of a disk latency heat map, and as a simple workload I ran tar(1) to archive the entire system. This turned out to be more than I had bargained for. Explaining it is pretty interesting, and demonstrates the different types of disk I/O heat maps you can generate on Linux.</p>

<h2>Latency Heat Map Generation</h2>

<p>In my previous post on Linux <a href="http://www.brendangregg.com/blog/2014-06-29/perf-static-tracepoints.html">perf static tracepoints</a>, I showed how the block:block_rq_complete probe provided a wealth of useful info by default. Along with the block:block_rq_issue probe, you can use the issue to complete tracepoint timestamps to calculate I/O time, or &quot;latency&quot;.</p>

<p>Here&#39;s how I captured the disk events:</p>

<pre>
# <b>perf record -e block:block_rq_issue -e block:block_rq_complete -a sleep 120</b>
[ perf record: Woken up 217 times to write data ]
[ perf record: Captured and wrote 54.507 MB perf.data (~2381448 samples) ]
# <b>perf script > out.blockio</b>
# <b>more out.blockio</b>
     tar 16072 [001] 2199495.030133: block:block_rq_issue: 202,16 R 0 () 21997888 + 8 [tar]
 swapper     0 [000] 2199495.030286: block:block_rq_complete: 202,16 R () 21997888 + 8 [0]
     tar 16072 [001] 2199495.030327: block:block_rq_issue: 202,16 R 0 () 21997896 + 8 [tar]
 swapper     0 [000] 2199495.030512: block:block_rq_complete: 202,16 R () 21997896 + 8 [0]
[...]
</pre>

<p>This uses <tt>perf</tt> to instrument both tracepoints for 120 seconds, then dumps the capture file to out.blockio: a text file of the data.</p>

<p>Here&#39;s the commands I used to generate the previous heatmaps. This includes trace2heatmap.pl, which you can download from my github <a href="https://github.com/brendangregg/HeatMap">HeatMap</a> project.</p>

<pre>
$ <b>awk '{ gsub(/:/, "") } $5 ~ /issue/ { ts[$6, $10] = $4 }
    $5 ~ /complete/ { if (l = ts[$6, $9]) { printf "%.f %.f\n", $4 * 1000000,
    ($4 - l) * 1000000; ts[$6, $10] = 0 } }' out.blockio > out.lat_us</b>
$ <b>./trace2heatmap.pl --unitstime=us --unitslat=us --grid out.lat_us > out.lat.svg</b>
$ <b>./trace2heatmap.pl --unitstime=us --unitslat=us --grid --maxlat=15000 \
    --title="Latency Heat Map: 15ms max" out.lat_us > out.latzoom.svg</b>
</pre>

<p>The trace2heatmap.pl program takes two columns: a timestamp and a latency. I used awk to associate block_rq_issue timestamps with block_rq_complete, based on the device ID and offset, so that latency can be calculated from their timestamps.</p>

<p>You might need to adjust the field numbers ($4, $5, ...) to match your output, as the perf_events tracepoints can change between kernel versions. This kernel version is 3.14.5.</p>

<p>If you want, you can combine steps to skip the intermediate files. I find them handy to browse, to look for patterns event by event.</p>

<h2>Size Heat Map</h2>

<p>There are two main workload factors that cause SSDs to perform differently: reads vs writes, and I/O size. As this is archiving an entire system, it might have encountered larger files at the 43 second mark, changing the I/O sizes used.</p>

<p>I/O size information is part of the capture I already have: field 11, in sectors. Building an I/O size heat map:</p>

<pre>
$ <b>awk '{ gsub(/:/, "") } $5 ~ /complete/ { print $4 * 1000000, ($11 * 512) }' \
    out.blockio > out.sizes</b>
$ <b>./trace2heatmap.pl --unitstime=us --unitslat=bytes out.sizes \
    --title="Size Heat Map" > out.sizes.svg</b>
</pre>

<p>Produces (<a href="/blog/images/2014/out.sizes.svg">SVG</a>):</p>

<p><object data="/blog/images/2014/out.sizes.svg" type="image/svg+xml" width=720 height=363>
<img src="/blog/images/2014/out.sizes.png" width=720 height=363 />
</object></p>

<p>The y-axis is now I/O size. In this case, that&#39;s not consistent with the latency seen. I/O size actually tends to be smaller after 43 seconds, not larger, which should mean quicker I/O...</p>

<h2>Offset Heat Map</h2>

<p>It&#39;s worth showing the following while I&#39;m here, although it shouldn&#39;t make much difference for SSDs: the disk I/O offset heat map. This uses the sector offset field from the block_rq_complete probe.</p>

<pre>
$ <b>awk '{ gsub(/:/, "") } $5 ~ /complete/ { print $4 * 1000000, ($9 * 512) / (1024 * 1024) }' \
    out.blockio > out.offset</b>
$ <b>./trace2heatmap.pl --unitstime=us --unitslat=Mbytes out.offset \
    --title="Offset Heat Map" > out.offset.svg</b>
</pre>

<p>Produces (<a href="/blog/images/2014/out.offset.svg">SVG</a>):</p>

<p><object data="/blog/images/2014/out.offset.svg" type="image/svg+xml" width=720 height=363>
<img src="/blog/images/2014/out.offset.png" width=720 height=363 />
</object></p>

<p>You can use this to quickly identify random disk I/O vs sequential, based on the spread of the offset distribution. For rotational disks this can make a 10x difference to the delivered latency (although to do this properly, you should generate a heat map for each disk). For SSDs it shouldn&#39;t matter: no mechanical disk arm to move, or platter to wait for rotation.</p>

<p>Something does happen at the 43 second mark. Before that, I/O looks quite random across the 16 Gbyte range (size of each SSD). After that, the pattern shows more sequential components. In fact, it looks a bit like a file system optimizing placement for rotational disks. Am I sure that I&#39;m only looking at SSDs here?</p>

<h2>SSD Latency Only</h2>

<p>My archive workload read all file systems, including the boot drive. For this instance, that&#39;s rotational magnetic disks. I can exclude it from my heat map by filtering the device ID, which was &quot;202,1&quot; (you&#39;ll need to adjust this to match your instance type):</p>

<pre>
$ awk '{ gsub(/:/, "") } $5 ~ /issue/ && <b>$6 != "202,1"</b> { ts[$6, $10] = $4 }
    $5 ~ /complete/ { if (l = ts[$6, $9]) { printf "%.f %.f\n", $4 * 1000000,
    ($4 - l) * 1000000; ts[$6, $10] = 0 } }' out.blockio > out.ssd_lat
$ <b>./trace2heatmap.pl --unitstime=us --unitslat=us \
    --title="Latency Heat Map: SSDs only" out.ssd_lat > out.ssd.svg</b>
</pre>

<p>This produces a heat map that shows SSD I/O only (<a href="/blog/images/2014/out.ssd.svg">SVG</a>):</p>

<p><object data="/blog/images/2014/out.ssd.svg" type="image/svg+xml" width=720 height=363>
<img src="/blog/images/2014/out.ssd.png" width=720 height=363 />
</object></p>

<p>All right! So the latency cloud and spikes after 43 were fore rotational disk I/O only, not SSD.</p>

<h2>Read Latency Only</h2>

<p>I&#39;ve seen such latency spikes before, caused by flushing batches of writes. Filtering out writes:</p>

<pre>
$ awk '{ gsub(/:/, "") } $5 ~ /issue/ && <b>$7 ~ /R/</b> { ts[$6, $10] = $4 }
    $5 ~ /complete/ { if (l = ts[$6, $9]) { printf "%.f %.f\n", $4 * 1000000,
    ($4 - l) * 1000000; ts[$6, $10] = 0 } }' out.blockio > out.read_lat
$ <b>./trace2heatmap.pl --unitstime=us --unitslat=us out.read_lat > out.read.svg</b>
</pre>

<p>Produces (<a href="/blog/images/2014/out.read.svg">SVG</a>):</p>

<p><object data="/blog/images/2014/out.read.svg" type="image/svg+xml" width=720 height=363>
<img src="/blog/images/2014/out.read.png" width=720 height=363 />
</object></p>

<p>Ah, latency spikes gone. These are bursts of writes, likely file system flushes. Also notice that the reads were unaffected: what&#39;s likely happening is that the disk devices are prioritizing reads over writes.</p>

<h2>Conclusion</h2>

<p>While the main storage on my c3.large is SSDs, my example workload accessed the rotational boot disk, changing the latency distribution dramatically. It&#39;s an easy configuration mistake to watch out for. There were also occasions where bursts of writes to this disk occurred, likely file system flushes, causing spikes in latency. These are normal, and usually don&#39;t affect synchronous I/O (drives can queue and service these differently).</p>

<p>These behaviors were visualized using heat maps for latency, I/O size, and I/O offset. These were generated using Linux <a href="/perf.html">perf_events</a> to capture disk I/O events, some awk to process the output, and my <a href="https://github.com/brendangregg/HeatMap">heat map</a> (github) software. You can do this too. Usual warning applys about running commands as root in production: understand what you are doing first.</p>

</div>



<br><hr>
<div id="disqus_thread"></div>
<script type="text/javascript">
var disqus_shortname = 'brendangregg';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


          <div class="footer">
            <div class="contact">
                Copyright 2014 Brendan Gregg.<br><a href="/blog/about.html">About this blog</a>
            </div>
          </div>
        </div>

    </body>
</html>
